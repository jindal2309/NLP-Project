{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "nlp_project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcFR8EacppUp",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uR5mEik19lj5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Supress unnecessary warnings so that presentation looks clean\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVLF3hXNe4b9",
        "colab_type": "code",
        "outputId": "31f1a61c-5fe4-4288-c1e0-2b9ab73ef712",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn import decomposition, ensemble\n",
        "\n",
        "import pandas, xgboost, numpy, textblob, string\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras import layers, models, optimizers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsyHONuffyvp",
        "colab_type": "code",
        "outputId": "249c2df2-3a4b-489b-9c29-c587a1de1015",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Google Colab stuff\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_SwTXvse4cK",
        "colab_type": "code",
        "outputId": "dc896eaf-c3d5-498e-f7f4-e4bc7ef68ecc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "# create a dataframe using texts and lables\n",
        "trainDF = train = pd.read_csv('/content/drive/My Drive/Colab Notebooks/NLP/data/training_data.csv')\n",
        "trainDF.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>text</th>\n",
              "      <th>ideas_content</th>\n",
              "      <th>organization</th>\n",
              "      <th>voice</th>\n",
              "      <th>word_choice</th>\n",
              "      <th>sentence_fluency</th>\n",
              "      <th>conventions</th>\n",
              "      <th>Unnamed: 8</th>\n",
              "      <th>Unnamed: 9</th>\n",
              "      <th>Unnamed: 10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>A long time ago when I was in third grade I h...</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Softball has to be one of the single most gre...</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Some people like making people laugh, I love ...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>\"LAUGHTER\"  @CAPS1 I hang out with my friends...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Well ima tell a story about the time i got @CA...</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   essay_id  ... Unnamed: 10\n",
              "0         1  ...         NaN\n",
              "1         2  ...         NaN\n",
              "2         3  ...         NaN\n",
              "3         4  ...         NaN\n",
              "4         5  ...         NaN\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4s0xoAag399",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "955c474c-da90-4574-c500-95fee8f7798d"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQDlhxcSgud1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "7d5a569a-1495-4415-fe41-02152369d29f"
      },
      "source": [
        "class Dataset:\n",
        "    def __init__(self, path):\n",
        "\n",
        "        self.df = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/NLP/data/training_data.csv\")\n",
        "        self.data = self.df.to_numpy()\n",
        "\n",
        "\n",
        "\n",
        "        self.stopwords = set(stopwords.words('english'))\n",
        "        self.essay_id = self.data[:,0]\n",
        "        self.text = self.data[:,1]\n",
        "        self.scores = self.data[:,2:8]\n",
        "        self.new_data = []\n",
        "        self.vocab = set()\n",
        "        self.word_to_id = None\n",
        "\n",
        "    def preprocess(self):\n",
        "        for i in range(len(self.essay_id)):\n",
        "            text = self.text[i].lower()\n",
        "            text = \" \".join([word for word in text.split() if '@' not in word])\n",
        "            text = word_tokenize(text)\n",
        "            text = [word for word in text if word not in self.stopwords]\n",
        "            self.text[i] = text \n",
        "\n",
        "    def create_vocab(self):\n",
        "        for line in self.text:\n",
        "            for word in line:\n",
        "                self.vocab.add(word)\n",
        "\n",
        "        self.vocab = sorted(list(self.vocab))\n",
        "        self.word_to_id = {word:i for i, word in enumerate(self.vocab)}\n",
        "\n",
        "    def create_chunks(self):\n",
        "        for idx in range(len(self.essay_id)):\n",
        "            ess = self.text[idx]\n",
        "            n = len(ess)\n",
        "            self.new_data.append([ess[:n//3], self.scores[idx]])\n",
        "            self.new_data.append([ess[n//3:2*n//3], self.scores[idx]])\n",
        "            self.new_data.append([ess[2*n//3:], self.scores[idx]])\n",
        "        self.new_data = np.array(self.new_data)\n",
        "\n",
        "    def text_num(self):\n",
        "        for i, line in enumerate(self.text):\n",
        "            x = []\n",
        "            for word in line:\n",
        "                x.append(self.word_to_id[word])\n",
        "            self.text[i] = x\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import nltk\n",
        "#nltk.download()\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "dataset = Dataset(\"/content/drive/My Drive/Colab Notebooks/NLP/data/training_data.csv\")\n",
        "\n",
        "dataset.preprocess()\n",
        "dataset.create_vocab()\n",
        "print(len(dataset.vocab))\n",
        "print(dataset.vocab[:10])\n",
        "print(dataset.word_to_id['!'])\n",
        "dataset.create_chunks()\n",
        "print(dataset.text[0])\n",
        "\"\"\"\n",
        "print(len(dataset.new_data), len(dataset.essay_id))\n",
        "print(\"0: \", dataset.new_data[0, 0])\n",
        "print(\"1: \", dataset.new_data[1, 0])\n",
        "print(\"2: \", dataset.new_data[2, 0])\n",
        "print(dataset.text[0])\n",
        "\"\"\""
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12527\n",
            "['!', '&', \"'\", \"''\", \"''cracked\", \"''from\", \"''i\", \"''laughter\", \"'d\", \"'em\"]\n",
            "0\n",
            "['long', 'time', 'ago', 'third', 'grade', 'friend', \"'s\", 'mom', 'bad', 'mood', '.', 'never', 'laughed', 'never', 'smiled', '.', 'every', 'time', 'saw', 'would', 'smile', 'would', 'frown', 'keep', 'walking', '.', 'first', \"n't\", 'know', 'grouch', 'thought', \"n't\", 'like', 'something.when', 'told', 'mom', 'grouch', 'started', 'laugh', 'laugh', '.', 'asked', 'funny', 'told', 'thought', 'mom', \"n't\", 'like', 'something', 'every', 'time', 'see', 'mom', 'would', 'smile', 'frown', 'walk', 'away', '.', 'made', 'friend', 'laugh', 'cracking', 'hard', 'got', 'trouble', 'class', '.', 'next', 'day', 'eating', 'lunch', 'school', 'says', '&', 'lt', ';', 'hey', 'pretty', 'good', 'making', 'people', 'laugh', '&', 'gt', ';', '.', 'said', '&', 'lt', ';', 'jokesare', 'horrible', '&', 'gt', ';', '.', 'said', 'lets', 'put', 'test', 'go', 'one', 'new', 'school', '&', 'gt', ';', '.', 'said', 'went', 'around', 'whole', 'school', 'looking', 'new', 'student', 'unfortunately', 'could', \"n't\", 'find', 'one', 'heard', 'bell', 'ring', 'ran', 'class', '.', 'sat', 'back', 'classroom', 'anempty', 'seat', 'us', '.', 'excited', 'teacher', 'going', 'show', 'us', 'movie', '.', 'got', 'front', 'room', 'andclass', 'today', 'announcement', 'new', 'student', 'class', 'say', 'hello', 'walked', 'door', '.', 'told', 'shecould', 'sit', 'back', 'i.', 'sat', 'turned', 'us', 'said', 'hello', '.', 'gave', 'look', 'said', 'tell', 'joke', 'thumbs', '.', 'turned', 'said', 'hi', \"'m\", 'want', 'hear', 'joke', '.', 'said', 'yeah', 'sure', '.', 'started', 'knockshe', 'said', '&', 'lt', ';', \"'s\", 'therei', 'said', '&', 'lt', ';', 'booshe', 'said', '&', 'lt', ';', 'boo', '?', 'said', '&', 'lt', ';', 'oh', \"n't\", 'cry', 'right', '&', 'gt', ';', '.', 'first', \"n't\", 'laugh', \"n't\", 'get', 'duringthe', 'middle', 'movie', 'said', '&', 'lt', ';', 'ohhhh', 'get', 'itand', 'started', 'laugh', '.', 'turned', 'said', '&', 'lt', ';', 'told', '&', 'gt', ';', '.', 'got', 'crazy', 'idea', 'spent', 'night', 'house', 'could', 'make', 'mom', 'laugh', 'least', 'make', 'smile', '.', 'said', 'sounds', 'like', 'plan', '&', 'gt', ';', '.', 'asked', 'mt', 'mom', 'could', 'spend', 'night', 'house', 'said', '&', 'lt', ';', 'yeah', 'make', 'sure', 'mom', '&', 'gt', ';', '.', 'asked', 'mom', 'said', 'got', 'house', 'first', 'thing', 'play', 'video', 'games', '.', 'dinner', 'time', 'sat', 'table', 'eat', 'one', 'side', 'parents', '.', 'started', 'eating', 'told', 'tell', 'joke', 'parents', 'said', 'said', 'replied', '&', 'lt', ';', \"'s\", 'therei', 'said', '&', 'lt', ';', 'boothey', 'said', '&', 'lt', ';', 'boo', '?', 'said', '&', 'lt', ';', 'oh', \"n't\", 'cry', 'right', '&', 'gt', ';', '.', 'parents', 'started', 'laugh', 'laugh', 'keptlaughing', 'like', 'five', 'minutes', '.', 'turned', 'yelled', 'worked', 'mom', 'asked', 'worked', '.', 'explained', 'everything', '.', 'mom', 'told', 'usthat', 'mom', 'recently', 'died', \"'s\", 'bad', 'mood', '.', 'dinner', 'went', 'bed', 'fell', 'asleep', '.', 'next', 'morning', 'mom', 'came', 'pick', 'asked', 'sleep', 'went', '.', 'said', 'fun', 'made', 'people', 'laugh', '.', 'said', 'laughter', \"n't\", 'going', 'help', 'clean', 'roomall', 'could', 'say', 'gosh', 'darn', '.', 'fin']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nprint(len(dataset.new_data), len(dataset.essay_id))\\nprint(\"0: \", dataset.new_data[0, 0])\\nprint(\"1: \", dataset.new_data[1, 0])\\nprint(\"2: \", dataset.new_data[2, 0])\\nprint(dataset.text[0])\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k74Xz8gShd0-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset.text_num()\n",
        "train_x = dataset.text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lh4De-cl5Geh",
        "colab_type": "code",
        "outputId": "8e72aba0-6874-4977-8e35-725200f099d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "trainDF = trainDF[['text','organization']]\n",
        "trainDF.columns = ['text','label']\n",
        "trainDF.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A long time ago when I was in third grade I h...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Softball has to be one of the single most gre...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Some people like making people laugh, I love ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"LAUGHTER\"  @CAPS1 I hang out with my friends...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Well ima tell a story about the time i got @CA...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  label\n",
              "0   A long time ago when I was in third grade I h...      4\n",
              "1   Softball has to be one of the single most gre...      4\n",
              "2   Some people like making people laugh, I love ...      3\n",
              "3   \"LAUGHTER\"  @CAPS1 I hang out with my friends...      3\n",
              "4  Well ima tell a story about the time i got @CA...      2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ps66nTJce4cN",
        "colab_type": "code",
        "outputId": "964e1aeb-b1c4-45ef-8c2e-a2127f67c260",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "trainDF.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(723, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAc34uuSe4cb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split the dataset into training and validation datasets \n",
        "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(trainDF['text'], trainDF['label'])\n",
        "\n",
        "# label encode the target variable \n",
        "encoder = preprocessing.LabelEncoder()\n",
        "train_y = encoder.fit_transform(train_y)\n",
        "valid_y = encoder.fit_transform(valid_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lW6ScB4uPoXg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2d6e150b-bdf9-4a30-e0f1-27fe08f890ed"
      },
      "source": [
        "max_len = 0\n",
        "ind = 0\n",
        "for t in train_x:\n",
        "  if len(t.split()) > max_len:\n",
        "    max_len = len(t.split())\n",
        "max_len"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "856"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYsyi4k4Pnj6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a tokenizer \n",
        "token = text.Tokenizer()\n",
        "token.fit_on_texts(trainDF['text'])\n",
        "word_index = token.word_index\n",
        "\n",
        "# convert text to sequence of tokens and pad them to ensure equal length vectors \n",
        "train_seq_x = sequence.pad_sequences(token.texts_to_sequences(train_x), maxlen=max_len)\n",
        "valid_seq_x = sequence.pad_sequences(token.texts_to_sequences(valid_x), maxlen=max_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYSHVcklfnPB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "4485a767-1253-4cda-bb9c-308d4949d0e1"
      },
      "source": [
        "# create a count vectorizer object \n",
        "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
        "count_vect.fit(trainDF['text'])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
              "                strip_accents=None, token_pattern='\\\\w{1,}', tokenizer=None,\n",
              "                vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGkUkhtRf7G7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_len = len(count_vect.vocabulary_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYzJG9s59CDr",
        "colab_type": "code",
        "outputId": "58dbb40e-6cc8-475b-bb3f-20713e469e30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(train_seq_x.shape, train_y.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(542, 856) (542,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6H1EAlvu9VdO",
        "colab_type": "code",
        "outputId": "f911fd56-246c-47e5-e020-0fdd149db2b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "train_seq_x"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0, ...,   10, 5416,   52],\n",
              "       [   0,    0,    0, ...,  495,    4,  305],\n",
              "       [   0,    0,    0, ..., 5893,    3,  375],\n",
              "       ...,\n",
              "       [   0,    0,    0, ...,    8,    5,   56],\n",
              "       [   0,    0,    0, ...,   16,  166,   41],\n",
              "       [   0,    0,    0, ..., 4706,  773, 5811]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gYhZoLZXLos",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch import optim\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6ADZ04WWqnf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cpu')\n",
        "#'cuda:0' if torch.cuda.is_available() else 'cpu'  \n",
        "train_seq_x1 = torch.from_numpy(train_seq_x).to(torch.int64).to(device)\n",
        "train_y1 = torch.from_numpy(train_y).to(torch.int64).to(device)\n",
        "\n",
        "valid_seq_x1 = torch.from_numpy(valid_seq_x).to(torch.int64).to(device)\n",
        "valid_y1 = torch.from_numpy(valid_y).to(torch.int64).to(device)\n",
        "\n",
        "\n",
        "batch_size = 50\n",
        "train_loader = DataLoader(TensorDataset(train_seq_x1, train_y1), batch_size = batch_size, shuffle = True)\n",
        "valid_loader = DataLoader(TensorDataset(valid_seq_x1, valid_y1), batch_size = batch_size, shuffle = True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qvmSDaJjxgA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "57792b8f-46c8-47e2-ed2c-e151f36ee044"
      },
      "source": [
        "train_seq_x1.shape, train_y1.shape"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([542, 856]), torch.Size([542]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhZ1IFVnjVBW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "386d1cf3-9723-4364-a8df-673854160d5f"
      },
      "source": [
        "device"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FFL2oRnVW2G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class LSTM_Model(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_size, hidden_num, output_num, layer_num):\n",
        "      super().__init__()\n",
        "      self.vocab_size = vocab_size\n",
        "      self.layer_num = layer_num\n",
        "      self.hidden_num = hidden_num\n",
        "\n",
        "      self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
        "      self.lstm = nn.LSTM(embedding_size, hidden_num, layer_num)\n",
        "      self.fc = nn.Linear(hidden_num, output_num)\n",
        "      self.relu = nn.ReLU()\n",
        "\n",
        "        \n",
        "    def forward(self, word_seq):\n",
        "      word_emb = self.embedding(word_seq)\n",
        "      lstm_out,h = self.lstm(word_emb)\n",
        "      lstm_out = lstm_out.contiguous().view(-1, self.hidden_num)\n",
        "      fc_out = self.fc(lstm_out)\n",
        "      relu_out = self.relu(fc_out)\n",
        "      relu_out = relu_out.view(batch_size, -1) \n",
        "      relu_out = relu_out[:,-1]\n",
        "      return relu_out, h\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZNi35bKWXt7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "95e14452-78fe-4651-ed79-e83f160825ae"
      },
      "source": [
        "train_seq_x.shape"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(542, 856)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52hmyt9hVW_h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(data_loader, classifier, loss_function, optimizer):\n",
        "    classifier.train()\n",
        "    loss = 0\n",
        "    losses = []\n",
        "    \n",
        "    accuracy = 0\n",
        "    accuracies = []\n",
        "    for i, (texts, labels) in enumerate(data_loader):\n",
        "      \n",
        "        if(texts.shape[0] != batch_size):\n",
        "            break\n",
        "        labels = labels.float()\n",
        "        # texts = texts.cuda()\n",
        "        # labels = labels.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        predictions,h = classifier(texts)\n",
        "        print(predictions.type(), labels.type())\n",
        "        loss = loss_function(predictions, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss.item()) \n",
        "        # print(losses)       \n",
        "    return sum(losses)/len(losses)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAcYyhCiYgPW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_vocab = vocab_len + 1000\n",
        "# n_vocab = len(embedding_matrix)\n",
        "n_embed = 300\n",
        "n_hidden = 512\n",
        "n_output = 1\n",
        "n_layers = 2\n",
        "\n",
        "rnn_model = LSTM_Model(n_vocab, n_embed, n_hidden, n_output, n_layers)\n",
        "# rnn_model.cuda()\n",
        "loss_function = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(rnn_model.parameters(), lr=0.0001, momentum=0.9)\n",
        "epochs = 5\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmt60RhcVW92",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "34e38d14-029e-473f-a717-b39a2c3ce84b"
      },
      "source": [
        "for epoch in range(0, epochs):\n",
        "    print(\"epoch:\", epoch + 1)\n",
        "    training_loss = train(train_loader, rnn_model, loss_function, optimizer)\n",
        "    print(\"training_loss:\", training_loss)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1\n",
            "torch.FloatTensor torch.FloatTensor\n",
            "torch.FloatTensor torch.FloatTensor\n",
            "torch.FloatTensor torch.FloatTensor\n",
            "torch.FloatTensor torch.FloatTensor\n",
            "torch.FloatTensor torch.FloatTensor\n",
            "torch.FloatTensor torch.FloatTensor\n",
            "torch.FloatTensor torch.FloatTensor\n",
            "torch.FloatTensor torch.FloatTensor\n",
            "torch.FloatTensor torch.FloatTensor\n",
            "torch.FloatTensor torch.FloatTensor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpn2meSknDHB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wT9YqhRqOtKD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_seq_x.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drjDLIYyO8P9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_seq_x[42]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiUw3haeOw6x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_y.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eleP2T8vPEY8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_matrix.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_P8n6d6PGf6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_matrix[226].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4EGJwSW6axL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9MPQlXH8nVG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_XVP96a8nSB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}