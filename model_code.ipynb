{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "model_code.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcFR8EacppUp",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uR5mEik19lj5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Supress unnecessary warnings so that presentation looks clean\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsyHONuffyvp",
        "colab_type": "code",
        "outputId": "a9e2bb9d-e129-4ba3-a8ad-a29f3b05295a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        }
      },
      "source": [
        "# Google Colab stuff\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \"\"\"\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    235\u001b[0m       \u001b[0mauth_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\nEnter your authorization code:\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfifo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfifo_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0mfifo_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_getpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth_prompt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m       \u001b[0mwrote_to_fifo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwrote_to_fifo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mgetpass\u001b[0;34m(self, prompt, stream)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m         )\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4s0xoAag399",
        "colab_type": "code",
        "outputId": "ea103d15-36b6-4ea5-b29d-777b24c40cff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQDlhxcSgud1",
        "colab_type": "code",
        "outputId": "08538b89-dcf4-4dad-d6fa-130633c2968c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "class Dataset:\n",
        "    def __init__(self, path):\n",
        "\n",
        "        self.df = pd.read_csv(\"./training_data.csv\")\n",
        "        self.data = self.df.to_numpy()\n",
        "\n",
        "\n",
        "\n",
        "        self.stopwords = set(stopwords.words('english'))\n",
        "        self.essay_id = self.data[:,0]\n",
        "        self.text = self.data[:,1]\n",
        "        self.scores = self.data[:,2:8]\n",
        "        self.new_data = []\n",
        "        self.new_scores = []\n",
        "        self.vocab = set()\n",
        "        self.word_to_id = None\n",
        "\n",
        "    def preprocess(self):\n",
        "        for i in range(len(self.essay_id)):\n",
        "            text = self.text[i].lower()\n",
        "            text = \" \".join([word for word in text.split() if '@' not in word])\n",
        "            text = word_tokenize(text)\n",
        "            text = [word for word in text if word not in self.stopwords]\n",
        "            self.text[i] = text \n",
        "\n",
        "    def create_vocab(self):\n",
        "        for line in self.text:\n",
        "            for word in line:\n",
        "                self.vocab.add(word)\n",
        "\n",
        "        self.vocab = sorted(list(self.vocab))\n",
        "        self.word_to_id = {word:i for i, word in enumerate(self.vocab)}\n",
        "\n",
        "    def text_num(self):\n",
        "        for i, line in enumerate(self.text):\n",
        "            x = []\n",
        "            for word in line:\n",
        "                x.append(self.word_to_id[word])\n",
        "            self.text[i] = x\n",
        "\n",
        "    def create_chunks(self):\n",
        "        for idx in range(len(self.essay_id)):\n",
        "            ess = self.text[idx]\n",
        "            n = len(ess)\n",
        "            self.new_data.append([ess[:n//3]])\n",
        "            self.new_data.append([ess[n//3:2*n//3]])\n",
        "            self.new_data.append([ess[2*n//3:]])\n",
        "            self.new_scores.append(self.scores[idx])\n",
        "            self.new_scores.append(self.scores[idx])\n",
        "            self.new_scores.append( self.scores[idx])\n",
        "\n",
        "import pandas as pd\n",
        "import nltk\n",
        "#nltk.download()\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "dataset = Dataset(\"/content/drive/My Drive/Colab Notebooks/NLP/data/training_data.csv\")\n",
        "print(dataset.text.shape)\n",
        "dataset.preprocess()\n",
        "dataset.create_vocab()\n",
        "# print(len(dataset.vocab))\n",
        "# print(dataset.vocab[:10])\n",
        "# print(dataset.word_to_id['!'])\n",
        "# dataset.create_chunks()\n",
        "# print(dataset.new_data.shape)\n",
        "# print(dataset.text[0])\n",
        "\"\"\"\n",
        "print(len(dataset.new_data), len(dataset.essay_id))\n",
        "print(\"0: \", dataset.new_data[0, 0])\n",
        "print(\"1: \", dataset.new_data[1, 0])\n",
        "print(\"2: \", dataset.new_data[2, 0])\n",
        "print(dataset.text[0])\n",
        "\"\"\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(723,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nprint(len(dataset.new_data), len(dataset.essay_id))\\nprint(\"0: \", dataset.new_data[0, 0])\\nprint(\"1: \", dataset.new_data[1, 0])\\nprint(\"2: \", dataset.new_data[2, 0])\\nprint(dataset.text[0])\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k74Xz8gShd0-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset.text_num()\n",
        "dataset.create_chunks()\n",
        "train_text = dataset.new_data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mnweWEuivIX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_len = 0\n",
        "for row in train_text:\n",
        "  leng = len(row[0])\n",
        "  if leng > max_len:\n",
        "    max_len = leng"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pY4H6rkwlEse",
        "colab_type": "code",
        "outputId": "f0f5cc71-7fb6-46c3-c298-1f33789e1907",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_len"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "185"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-WromJsl6Ix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_text = [train_text[i][0] for i in range(len(train_text))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGRgK_Xei78d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Padding with space (0)\n",
        "for i in range(len(train_text)):\n",
        "    while len(train_text[i])<=max_len:\n",
        "        train_text[i].append(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbsMUIRtiSwW",
        "colab_type": "code",
        "outputId": "62a39c8b-12cf-4792-f679-ce23fc0f2c29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_label = dataset.new_scores\n",
        "len(train_label)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2169"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4maWqmMAdykt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import model_selection\n",
        "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(train_text, train_label)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0IJEwHVlmFm",
        "colab_type": "code",
        "outputId": "36db44ab-d49d-4bd3-f0df-d23f70835d77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_x[0]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[11543,\n",
              " 10535,\n",
              " 11637,\n",
              " 2041,\n",
              " 4487,\n",
              " 943,\n",
              " 4487,\n",
              " 5989,\n",
              " 6237,\n",
              " 43,\n",
              " 7461,\n",
              " 12472,\n",
              " 1318,\n",
              " 7153,\n",
              " 12061,\n",
              " 10146,\n",
              " 4538,\n",
              " 5727,\n",
              " 11004,\n",
              " 10437,\n",
              " 9147,\n",
              " 8068,\n",
              " 11957,\n",
              " 4598,\n",
              " 2782,\n",
              " 43,\n",
              " 5165,\n",
              " 8057,\n",
              " 4479,\n",
              " 4420,\n",
              " 2460,\n",
              " 5964,\n",
              " 5204,\n",
              " 8057,\n",
              " 35,\n",
              " 3631,\n",
              " 4679,\n",
              " 7729,\n",
              " 8057,\n",
              " 5205,\n",
              " 771,\n",
              " 10379,\n",
              " 3789,\n",
              " 2460,\n",
              " 43,\n",
              " 4420,\n",
              " 3661,\n",
              " 8057,\n",
              " 7089,\n",
              " 6612,\n",
              " 6543,\n",
              " 4487,\n",
              " 43,\n",
              " 11252,\n",
              " 4538,\n",
              " 4704,\n",
              " 7153,\n",
              " 7138,\n",
              " 10938,\n",
              " 7089,\n",
              " 35,\n",
              " 6407,\n",
              " 7138,\n",
              " 11023,\n",
              " 12254,\n",
              " 6543,\n",
              " 7857,\n",
              " 43,\n",
              " 382,\n",
              " 11498,\n",
              " 6640,\n",
              " 6681,\n",
              " 4487,\n",
              " 2460,\n",
              " 8071,\n",
              " 10256,\n",
              " 7089,\n",
              " 11252,\n",
              " 4487,\n",
              " 2460,\n",
              " 43,\n",
              " 8057,\n",
              " 10402,\n",
              " 3628,\n",
              " 10402,\n",
              " 5061,\n",
              " 7449,\n",
              " 1427,\n",
              " 10402,\n",
              " 7797,\n",
              " 6456,\n",
              " 687,\n",
              " 4420,\n",
              " 1427,\n",
              " 6407,\n",
              " 380,\n",
              " 6103,\n",
              " 6405,\n",
              " 12127,\n",
              " 168,\n",
              " 606,\n",
              " 5965,\n",
              " 473,\n",
              " 8057,\n",
              " 7089,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUcxUrqCjkJg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_seq_x = np.array(train_x)\n",
        "valid_seq_x = np.array(valid_x)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgD4Srifkjty",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_y = np.array(train_y)[:,0]\n",
        "valid_y = np.array(valid_y)[:,0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGkUkhtRf7G7",
        "colab_type": "code",
        "outputId": "400f116e-4100-4dd6-daa1-84e9278b29ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab_len = len(dataset.vocab)\n",
        "vocab_len"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12527"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYzJG9s59CDr",
        "colab_type": "code",
        "outputId": "e0fbc0c0-49aa-418e-c8fc-bc396597d85c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(train_seq_x.shape, train_y.shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1626, 186) (1626,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSqIXoaqmSaz",
        "colab_type": "code",
        "outputId": "478d17bf-06dd-4aa1-f8a9-fae54f16e112",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(valid_seq_x.shape, valid_y.shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(543, 186) (543,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6H1EAlvu9VdO",
        "colab_type": "code",
        "outputId": "89ac1b51-c027-4adb-99f3-a273f4bdda6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "\n",
        "train_seq_x"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[11543, 10535, 11637, ...,     0,     0,     0],\n",
              "       [ 2044,  6365,    35, ...,     0,     0,     0],\n",
              "       [ 1040,  4479, 11598, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [   15,    66, 10229, ...,     0,     0,     0],\n",
              "       [ 3789,  6217,  5094, ...,     0,     0,     0],\n",
              "       [ 3789,  4116,  6405, ...,     0,     0,     0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-bExpfnd-5I",
        "colab_type": "code",
        "outputId": "3fa108ed-d34b-4e35-fec3-4dbb73f3d48e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_y = train_y.astype(float)\n",
        "valid_y = valid_y.astype(float)\n",
        "train_y"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3., 3., 5., ..., 3., 4., 3.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gYhZoLZXLos",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch import optim\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6ADZ04WWqnf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# device = torch.device('cpu')\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_seq_x1 = torch.from_numpy(train_seq_x).to(device)\n",
        "train_y1 = torch.from_numpy(train_y).to(device)\n",
        "\n",
        "valid_seq_x1 = torch.from_numpy(valid_seq_x).to(device)\n",
        "valid_y1 = torch.from_numpy(valid_y).to(device)\n",
        "\n",
        "\n",
        "batch_size = 3\n",
        "train_loader = DataLoader(TensorDataset(train_seq_x1, train_y1), batch_size = batch_size, shuffle = True)\n",
        "valid_loader = DataLoader(TensorDataset(valid_seq_x1, valid_y1), batch_size = batch_size, shuffle = True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qvmSDaJjxgA",
        "colab_type": "code",
        "outputId": "99afb71f-3796-4906-d0c3-54055c0dae9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_seq_x1.shape, train_y1.shape"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1626, 186]), torch.Size([1626]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhZ1IFVnjVBW",
        "colab_type": "code",
        "outputId": "b2d36c03-6226-462d-add2-09886f328a5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FFL2oRnVW2G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTM_Model(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_size, hidden_num, output_num, layer_num):\n",
        "      super().__init__()\n",
        "      self.vocab_size = vocab_size\n",
        "      self.layer_num = layer_num\n",
        "      self.hidden_num = hidden_num\n",
        "\n",
        "      self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
        "      self.lstm = nn.LSTM(embedding_size, hidden_num, layer_num)\n",
        "      self.fc = nn.Linear(hidden_num, output_num)\n",
        "      self.relu = nn.ReLU()\n",
        "\n",
        "        \n",
        "    def forward(self, word_seq):\n",
        "      word_emb = self.embedding(word_seq)\n",
        "      lstm_out,h = self.lstm(word_emb)\n",
        "      lstm_out = lstm_out.contiguous().view(-1, self.hidden_num)\n",
        "      fc_out = self.fc(lstm_out)\n",
        "      relu_out = self.relu(fc_out)\n",
        "      relu_out = relu_out.view(batch_size, -1) \n",
        "      relu_out = relu_out[:,-1]\n",
        "      return relu_out, h\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZNi35bKWXt7",
        "colab_type": "code",
        "outputId": "8f9be67f-c01a-44f8-e2e5-366943b4f478",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_seq_x.shape"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1626, 186)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52hmyt9hVW_h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(data_loader, classifier, loss_function, optimizer):\n",
        "    classifier.train()\n",
        "    loss = 0\n",
        "    losses = []\n",
        "    prediction_list = []\n",
        "    accuracy = 0\n",
        "    accuracies = []\n",
        "    for i, (texts, labels) in enumerate(data_loader):\n",
        "      \n",
        "        if(texts.shape[0] != batch_size):\n",
        "            break\n",
        "        labels = labels.float()\n",
        "        texts = texts.cuda()\n",
        "        labels = labels.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        predictions,h = classifier(texts)\n",
        "        # print(predictions.type(), labels.type())\n",
        "        loss = loss_function(torch.sum(predictions), torch.sum(labels)/len(labels))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss.item()) \n",
        "        prediction_list.append(predictions.cpu().data.numpy().tolist())\n",
        "        # print(losses)       \n",
        "    return prediction_list, sum(losses)/len(losses)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAcYyhCiYgPW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_vocab = vocab_len + 1000\n",
        "# n_vocab = len(embedding_matrix)\n",
        "n_embed = 300\n",
        "n_hidden = 512\n",
        "n_output = 1\n",
        "n_layers = 2\n",
        "\n",
        "rnn_model = LSTM_Model(n_vocab, n_embed, n_hidden, n_output, n_layers)\n",
        "rnn_model.cuda()\n",
        "loss_function = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(rnn_model.parameters(), lr=0.001, momentum=0.9)\n",
        "epochs = 5\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpn2meSknDHB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validation(data_loader, classifier, loss_function, optimizer):\n",
        "    classifier.eval()\n",
        "    loss = 0\n",
        "    losses = []\n",
        "    prediction_list = []\n",
        "    accuracy = 0\n",
        "    accuracies = []\n",
        "    for i, (texts, labels) in enumerate(data_loader):\n",
        "      \n",
        "        if(texts.shape[0] != batch_size):\n",
        "            break\n",
        "        labels = labels.float()\n",
        "        texts = texts.cuda()\n",
        "        labels = labels.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        predictions,h = classifier(texts)\n",
        "        # print(predictions.type(), labels.type())\n",
        "        loss = loss_function(torch.sum(predictions), labels)\n",
        "        losses.append(loss.item()) \n",
        "        prediction_list.append(predictions.cpu().data.numpy().tolist())\n",
        "        # print(losses)       \n",
        "    return prediction_list, sum(losses)/len(losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmt60RhcVW92",
        "colab_type": "code",
        "outputId": "33683690-0b77-41b7-836d-f965095b1ed8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        }
      },
      "source": [
        "epochs = 10\n",
        "\n",
        "for epoch in range(0, epochs):\n",
        "    print(\"epoch:\", epoch + 1)\n",
        "    train_predictions, training_loss = train(train_loader, rnn_model, loss_function, optimizer)\n",
        "    val_predictions, validation_loss = validation(valid_loader, rnn_model, loss_function, optimizer)\n",
        "    print(\"training_loss:\", training_loss)\n",
        "    print(\"validation_loss:\", validation_loss)\n"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1\n",
            "training_loss: 14.229807822906663\n",
            "validation_loss: 14.86187842405962\n",
            "epoch: 2\n",
            "training_loss: 14.233907872900312\n",
            "validation_loss: 14.86187838454273\n",
            "epoch: 3\n",
            "training_loss: 14.222017719296952\n",
            "validation_loss: 14.861878416156243\n",
            "epoch: 4\n",
            "training_loss: 14.227347761942452\n",
            "validation_loss: 14.861878455673134\n",
            "epoch: 5\n",
            "training_loss: 14.240877961760518\n",
            "validation_loss: 14.861878431962998\n",
            "epoch: 6\n",
            "training_loss: 14.228987859184011\n",
            "validation_loss: 14.861878434597457\n",
            "epoch: 7\n",
            "training_loss: 14.233497886200233\n",
            "validation_loss: 14.861878437231917\n",
            "epoch: 8\n",
            "training_loss: 14.222837758680111\n",
            "validation_loss: 14.861878463576511\n",
            "epoch: 9\n",
            "training_loss: 14.243337938266487\n",
            "validation_loss: 14.861878413521783\n",
            "epoch: 10\n",
            "training_loss: 14.236777910887096\n",
            "validation_loss: 14.8618784187907\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4EGJwSW6axL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9MPQlXH8nVG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKAndDymnJrS",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}