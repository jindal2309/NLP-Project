{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RcFR8EacppUp"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uR5mEik19lj5"
   },
   "outputs": [],
   "source": [
    "# Supress unnecessary warnings so that presentation looks clean\n",
    "import warnings\n",
    "from sklearn import model_selection\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "google_colab=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "dsyHONuffyvp",
    "outputId": "d1ad86e0-1667-4106-d2f8-ef8ece4b76c8"
   },
   "outputs": [],
   "source": [
    "if google_colab:\n",
    "    # Google Colab stuff\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 98
    },
    "colab_type": "code",
    "id": "n4s0xoAag399",
    "outputId": "dafb66e4-c2aa-46e2-977d-af2f8717cfa7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Patrick\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Patrick\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "OQDlhxcSgud1",
    "outputId": "f7d877d9-93e1-44a6-f110-c93294fbcd15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(723,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nprint(len(dataset.new_data), len(dataset.essay_id))\\nprint(\"0: \", dataset.new_data[0, 0])\\nprint(\"1: \", dataset.new_data[1, 0])\\nprint(\"2: \", dataset.new_data[2, 0])\\nprint(dataset.text[0])\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, path):\n",
    "        \n",
    "        if google_colab:\n",
    "            self.df = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/NLP/data/training_data.csv\")\n",
    "        else:\n",
    "            self.df = pd.read_csv(\"training_data.csv\")\n",
    "        self.data = self.df.to_numpy()\n",
    "\n",
    "        self.stopwords = set(stopwords.words('english'))\n",
    "        self.essay_id = self.data[:,0]\n",
    "        self.text = self.data[:,1]\n",
    "        self.scores = self.data[:,2:8]\n",
    "        self.new_data = []\n",
    "        self.new_scores = []\n",
    "        self.vocab = set()\n",
    "        self.word_to_id = None\n",
    "\n",
    "    def preprocess(self):\n",
    "        for i in range(len(self.essay_id)):\n",
    "            text = self.text[i].lower()\n",
    "            text = \" \".join([word for word in text.split() if '@' not in word])\n",
    "            text = word_tokenize(text)\n",
    "            text = [word for word in text if word not in self.stopwords]\n",
    "            self.text[i] = text \n",
    "\n",
    "    def create_vocab(self):\n",
    "        for line in self.text:\n",
    "            for word in line:\n",
    "                self.vocab.add(word)\n",
    "\n",
    "        self.vocab = sorted(list(self.vocab))\n",
    "        self.word_to_id = {word:i for i, word in enumerate(self.vocab)}\n",
    "\n",
    "    def text_num(self):\n",
    "        for i, line in enumerate(self.text):\n",
    "            x = []\n",
    "            for word in line:\n",
    "                x.append(self.word_to_id[word])\n",
    "            self.text[i] = x\n",
    "\n",
    "    def create_chunks(self):\n",
    "        for idx in range(len(self.essay_id)):\n",
    "            ess = self.text[idx]\n",
    "            n = len(ess)\n",
    "            self.new_data.append([ess[:n//3]])\n",
    "            self.new_data.append([ess[n//3:2*n//3]])\n",
    "            self.new_data.append([ess[2*n//3:]])\n",
    "            self.new_scores.append(self.scores[idx])\n",
    "            self.new_scores.append(self.scores[idx])\n",
    "            self.new_scores.append( self.scores[idx])\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "#nltk.download()\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "dataset = Dataset(\"/content/drive/My Drive/Colab Notebooks/NLP/data/training_data.csv\")\n",
    "print(dataset.text.shape)\n",
    "dataset.preprocess()\n",
    "dataset.create_vocab()\n",
    "# print(len(dataset.vocab))\n",
    "# print(dataset.vocab[:10])\n",
    "# print(dataset.word_to_id['!'])\n",
    "# dataset.create_chunks()\n",
    "# print(dataset.new_data.shape)\n",
    "# print(dataset.text[0])\n",
    "\"\"\"\n",
    "print(len(dataset.new_data), len(dataset.essay_id))\n",
    "print(\"0: \", dataset.new_data[0, 0])\n",
    "print(\"1: \", dataset.new_data[1, 0])\n",
    "print(\"2: \", dataset.new_data[2, 0])\n",
    "print(dataset.text[0])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k74Xz8gShd0-"
   },
   "outputs": [],
   "source": [
    "dataset.text_num()\n",
    "dataset.create_chunks()\n",
    "train_text = dataset.new_data\n",
    "\n",
    "max_len = 0\n",
    "for row in train_text:\n",
    "  leng = len(row[0])\n",
    "  if leng > max_len:\n",
    "    max_len = leng\n",
    "max_len\n",
    "\n",
    "train_text = [train_text[i][0] for i in range(len(train_text))]\n",
    "\n",
    "# Padding with space (0)\n",
    "for i in range(len(train_text)):\n",
    "    while len(train_text[i])<=max_len:\n",
    "        train_text[i].append(0)\n",
    "        \n",
    "train_label = dataset.new_scores\n",
    "len(train_label)\n",
    "\n",
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(train_text, train_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-mnweWEuivIX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12520\n",
      "(1626, 186) (1626,)\n",
      "(543, 186) (543,)\n"
     ]
    }
   ],
   "source": [
    "train_seq_x = np.array(train_x)\n",
    "valid_seq_x = np.array(valid_x)\n",
    "\n",
    "train_y = np.array(train_y)[:,0].astype(float)\n",
    "valid_y = np.array(valid_y)[:,0].astype(float)\n",
    "\n",
    "vocab_len = len(dataset.vocab)\n",
    "print(vocab_len)\n",
    "\n",
    "print(train_seq_x.shape, train_y.shape)\n",
    "\n",
    "print(valid_seq_x.shape, valid_y.shape)\n",
    "\n",
    "# train_y = train_y.astype(float)\n",
    "# valid_y = valid_y.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k6ADZ04WWqnf"
   },
   "outputs": [],
   "source": [
    "# device = torch.device('cpu')\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if google_colab:\n",
    "    train_seq_x1 = torch.from_numpy(train_seq_x).to(device)\n",
    "    train_y1 = torch.from_numpy(train_y).to(device)\n",
    "    valid_seq_x1 = torch.from_numpy(valid_seq_x).to(device)\n",
    "    valid_y1 = torch.from_numpy(valid_y).to(device)\n",
    "else:\n",
    "    train_seq_x1 = torch.from_numpy(train_seq_x).to(torch.int64).to(device)\n",
    "    train_y1 = torch.from_numpy(train_y).to(torch.int64).to(device)\n",
    "    valid_seq_x1 = torch.from_numpy(valid_seq_x).to(torch.int64).to(device)\n",
    "    valid_y1 = torch.from_numpy(valid_y).to(torch.int64).to(device)\n",
    "\n",
    "batch_size = 100\n",
    "train_loader = DataLoader(TensorDataset(train_seq_x1, train_y1), batch_size = batch_size, shuffle = True)\n",
    "valid_loader = DataLoader(TensorDataset(valid_seq_x1, valid_y1), batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2FFL2oRnVW2G"
   },
   "outputs": [],
   "source": [
    "class LSTM_Model(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_num, output_num, layer_num):\n",
    "      super().__init__()\n",
    "      self.vocab_size = vocab_size\n",
    "      self.layer_num = layer_num\n",
    "      self.hidden_num = hidden_num\n",
    "\n",
    "      self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "      self.lstm = nn.LSTM(embedding_size, hidden_num, layer_num)\n",
    "      self.fc = nn.Linear(hidden_num, output_num)\n",
    "      self.relu = nn.ReLU()\n",
    "\n",
    "      self.hidden = (torch.randn(self.layer_num, max_len+1, self.hidden_num).cuda(), torch.randn(self.layer_num, max_len+1, self.hidden_num).cuda())\n",
    "    \n",
    "    def forward(self, word_seq):\n",
    "      word_emb = self.embedding(word_seq)\n",
    "      self.hidden = (torch.randn(self.layer_num, max_len+1, self.hidden_num).cuda(), torch.randn(self.layer_num, max_len+1, self.hidden_num).cuda())\n",
    "      lstm_out,self.hidden = self.lstm(word_emb, self.hidden)\n",
    "      lstm_out = lstm_out.contiguous().view(-1, self.hidden_num)\n",
    "      fc_out = self.fc(lstm_out)\n",
    "      relu_out = self.relu(fc_out)\n",
    "      relu_out = relu_out.view(batch_size, -1) \n",
    "      relu_out = relu_out[:,-1]\n",
    "      return relu_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "TZNi35bKWXt7",
    "outputId": "701506ab-d8dc-4c9e-f130-fcbbf9c548a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1626, 186)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_seq_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "52hmyt9hVW_h"
   },
   "outputs": [],
   "source": [
    "def train(data_loader, classifier, loss_function, optimizer):\n",
    "    classifier.train()\n",
    "    loss = 0\n",
    "    losses = []\n",
    "    prediction_list = []\n",
    "    accuracy = 0\n",
    "    accuracies = []\n",
    "    for i, (texts, labels) in enumerate(data_loader):\n",
    "      \n",
    "        if(texts.shape[0] != batch_size):\n",
    "            break\n",
    "        labels = labels.float()\n",
    "        texts = texts.cuda()\n",
    "        labels = labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        predictions = classifier(texts)\n",
    "        # print(predictions.type(), labels.type())\n",
    "        loss = loss_function(predictions, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item()) \n",
    "        prediction_list.append([(predictions[i].item(), labels[i].item()) for i in range(len(predictions))])\n",
    "        # print(losses)       \n",
    "    return prediction_list, sum(losses)/len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pAcYyhCiYgPW"
   },
   "outputs": [],
   "source": [
    "n_vocab = vocab_len# + 1000\n",
    "# n_vocab = len(embedding_matrix)\n",
    "n_embed = 1000\n",
    "n_hidden = 256\n",
    "n_output = 1\n",
    "n_layers = 2\n",
    "\n",
    "rnn_model = LSTM_Model(n_vocab, n_embed, n_hidden, n_output, n_layers)\n",
    "rnn_model.cuda()\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(rnn_model.parameters(), lr=0.001)\n",
    "epochs = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zpn2meSknDHB"
   },
   "outputs": [],
   "source": [
    "def validation(data_loader, classifier, loss_function, optimizer):\n",
    "    classifier.eval()\n",
    "    loss = 0\n",
    "    losses = []\n",
    "    prediction_list = []\n",
    "    accuracy = 0\n",
    "    accuracies = []\n",
    "    for i, (texts, labels) in enumerate(data_loader):\n",
    "      \n",
    "        if(texts.shape[0] != batch_size):\n",
    "            break\n",
    "        labels = labels.float()\n",
    "        texts = texts.cuda()\n",
    "        labels = labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        predictions = classifier(texts)\n",
    "        # print(predictions.type(), labels.type())\n",
    "        loss = loss_function(predictions, labels)\n",
    "        losses.append(loss.item()) \n",
    "        prediction_list.append([(predictions[i].item(), labels[i].item()) for i in range(len(predictions))])\n",
    "        # print(losses)       \n",
    "    return prediction_list, sum(losses)/len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(predictions):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch in predictions:\n",
    "        for item in batch:\n",
    "            if int(round(item[0])) == int(item[1]):\n",
    "                correct += 1\n",
    "            total += 1\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 505
    },
    "colab_type": "code",
    "id": "nmt60RhcVW92",
    "outputId": "5d29dbf2-e222-4573-9b05-19d2b8936ee1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "training_loss: 2.4656851701438427\n",
      "validation_loss: 0.7427350759506226\n",
      "train_accuracy: 0.315\n",
      "validation_accuracy: 0.264\n",
      "epoch: 2\n",
      "training_loss: 0.6506977863609791\n",
      "validation_loss: 0.5784127533435821\n",
      "train_accuracy: 0.530625\n",
      "validation_accuracy: 0.584\n",
      "epoch: 3\n",
      "training_loss: 0.5892071221023798\n",
      "validation_loss: 0.5945849597454071\n",
      "train_accuracy: 0.543125\n",
      "validation_accuracy: 0.588\n",
      "epoch: 4\n",
      "training_loss: 0.5617428384721279\n",
      "validation_loss: 0.570533174276352\n",
      "train_accuracy: 0.55\n",
      "validation_accuracy: 0.59\n",
      "epoch: 5\n",
      "training_loss: 0.5428692288696766\n",
      "validation_loss: 0.566394180059433\n",
      "train_accuracy: 0.555\n",
      "validation_accuracy: 0.588\n",
      "epoch: 6\n",
      "training_loss: 0.5627081245183945\n",
      "validation_loss: 0.563042676448822\n",
      "train_accuracy: 0.545\n",
      "validation_accuracy: 0.588\n",
      "epoch: 7\n",
      "training_loss: 0.5657030865550041\n",
      "validation_loss: 0.5605938792228699\n",
      "train_accuracy: 0.54625\n",
      "validation_accuracy: 0.588\n",
      "epoch: 8\n",
      "training_loss: 0.541326055303216\n",
      "validation_loss: 0.550516015291214\n",
      "train_accuracy: 0.55\n",
      "validation_accuracy: 0.588\n",
      "epoch: 9\n",
      "training_loss: 0.5412488505244255\n",
      "validation_loss: 0.5486313462257385\n",
      "train_accuracy: 0.551875\n",
      "validation_accuracy: 0.588\n",
      "epoch: 10\n",
      "training_loss: 0.5472279936075211\n",
      "validation_loss: 0.5415170133113861\n",
      "train_accuracy: 0.549375\n",
      "validation_accuracy: 0.588\n",
      "epoch: 11\n",
      "training_loss: 0.5409671198576689\n",
      "validation_loss: 0.5333866953849793\n",
      "train_accuracy: 0.544375\n",
      "validation_accuracy: 0.588\n",
      "epoch: 12\n",
      "training_loss: 0.5435174033045769\n",
      "validation_loss: 0.5486716806888581\n",
      "train_accuracy: 0.55\n",
      "validation_accuracy: 0.584\n",
      "epoch: 13\n",
      "training_loss: 0.5439499113708735\n",
      "validation_loss: 0.5379880607128144\n",
      "train_accuracy: 0.551875\n",
      "validation_accuracy: 0.582\n",
      "epoch: 14\n",
      "training_loss: 0.5268846768885851\n",
      "validation_loss: 0.5293724417686463\n",
      "train_accuracy: 0.55\n",
      "validation_accuracy: 0.584\n",
      "epoch: 15\n",
      "training_loss: 0.5222067907452583\n",
      "validation_loss: 0.528589516878128\n",
      "train_accuracy: 0.551875\n",
      "validation_accuracy: 0.584\n",
      "epoch: 16\n",
      "training_loss: 0.5325611382722855\n",
      "validation_loss: 0.5361090362071991\n",
      "train_accuracy: 0.55375\n",
      "validation_accuracy: 0.584\n",
      "epoch: 17\n",
      "training_loss: 0.5235135965049267\n",
      "validation_loss: 0.5157014608383179\n",
      "train_accuracy: 0.554375\n",
      "validation_accuracy: 0.582\n",
      "epoch: 18\n",
      "training_loss: 0.5249861590564251\n",
      "validation_loss: 0.5222169935703278\n",
      "train_accuracy: 0.549375\n",
      "validation_accuracy: 0.582\n",
      "epoch: 19\n",
      "training_loss: 0.5288753472268581\n",
      "validation_loss: 0.5123658895492553\n",
      "train_accuracy: 0.55375\n",
      "validation_accuracy: 0.582\n",
      "epoch: 20\n",
      "training_loss: 0.5426440127193928\n",
      "validation_loss: 0.5264778673648834\n",
      "train_accuracy: 0.55\n",
      "validation_accuracy: 0.582\n",
      "epoch: 21\n",
      "training_loss: 0.5097379367798567\n",
      "validation_loss: 0.5174564301967621\n",
      "train_accuracy: 0.55625\n",
      "validation_accuracy: 0.582\n",
      "epoch: 22\n",
      "training_loss: 0.5171315912157297\n",
      "validation_loss: 0.5076921999454498\n",
      "train_accuracy: 0.555625\n",
      "validation_accuracy: 0.584\n",
      "epoch: 23\n",
      "training_loss: 0.5073736291378736\n",
      "validation_loss: 0.5054134011268616\n",
      "train_accuracy: 0.5575\n",
      "validation_accuracy: 0.582\n",
      "epoch: 24\n",
      "training_loss: 0.5113112181425095\n",
      "validation_loss: 0.5137248933315277\n",
      "train_accuracy: 0.550625\n",
      "validation_accuracy: 0.582\n",
      "epoch: 25\n",
      "training_loss: 0.5110553875565529\n",
      "validation_loss: 0.5015335738658905\n",
      "train_accuracy: 0.553125\n",
      "validation_accuracy: 0.586\n",
      "epoch: 26\n",
      "training_loss: 0.5148314144462347\n",
      "validation_loss: 0.49725682735443116\n",
      "train_accuracy: 0.556875\n",
      "validation_accuracy: 0.59\n",
      "epoch: 27\n",
      "training_loss: 0.5153781622648239\n",
      "validation_loss: 0.5017168700695038\n",
      "train_accuracy: 0.553125\n",
      "validation_accuracy: 0.586\n",
      "epoch: 28\n",
      "training_loss: 0.5123638492077589\n",
      "validation_loss: 0.5006609380245208\n",
      "train_accuracy: 0.55375\n",
      "validation_accuracy: 0.586\n",
      "epoch: 29\n",
      "training_loss: 0.51055739633739\n",
      "validation_loss: 0.5040652036666871\n",
      "train_accuracy: 0.554375\n",
      "validation_accuracy: 0.586\n",
      "epoch: 30\n",
      "training_loss: 0.5182040575891733\n",
      "validation_loss: 0.5221607208251953\n",
      "train_accuracy: 0.555625\n",
      "validation_accuracy: 0.59\n",
      "epoch: 31\n",
      "training_loss: 0.5157358627766371\n",
      "validation_loss: 0.5012317061424255\n",
      "train_accuracy: 0.55625\n",
      "validation_accuracy: 0.588\n",
      "epoch: 32\n",
      "training_loss: 0.5103642400354147\n",
      "validation_loss: 0.4968724727630615\n",
      "train_accuracy: 0.555625\n",
      "validation_accuracy: 0.588\n",
      "epoch: 33\n",
      "training_loss: 0.5182794537395239\n",
      "validation_loss: 0.5002470314502716\n",
      "train_accuracy: 0.5575\n",
      "validation_accuracy: 0.588\n",
      "epoch: 34\n",
      "training_loss: 0.5186925008893013\n",
      "validation_loss: 0.5108516156673432\n",
      "train_accuracy: 0.553125\n",
      "validation_accuracy: 0.588\n",
      "epoch: 35\n",
      "training_loss: 0.5232481434941292\n",
      "validation_loss: 0.5127189517021179\n",
      "train_accuracy: 0.555\n",
      "validation_accuracy: 0.586\n",
      "epoch: 36\n",
      "training_loss: 0.5164109226316214\n",
      "validation_loss: 0.4975965738296509\n",
      "train_accuracy: 0.55625\n",
      "validation_accuracy: 0.59\n",
      "epoch: 37\n",
      "training_loss: 0.5105939134955406\n",
      "validation_loss: 0.498363995552063\n",
      "train_accuracy: 0.55625\n",
      "validation_accuracy: 0.59\n",
      "epoch: 38\n",
      "training_loss: 0.5089502520859241\n",
      "validation_loss: 0.497954398393631\n",
      "train_accuracy: 0.554375\n",
      "validation_accuracy: 0.588\n",
      "epoch: 39\n",
      "training_loss: 0.5116666294634342\n",
      "validation_loss: 0.5107190549373627\n",
      "train_accuracy: 0.55375\n",
      "validation_accuracy: 0.588\n",
      "epoch: 40\n",
      "training_loss: 0.516608864068985\n",
      "validation_loss: 0.4989212453365326\n",
      "train_accuracy: 0.553125\n",
      "validation_accuracy: 0.59\n",
      "epoch: 41\n",
      "training_loss: 0.5160724502056837\n",
      "validation_loss: 0.5103658616542817\n",
      "train_accuracy: 0.556875\n",
      "validation_accuracy: 0.586\n",
      "epoch: 42\n",
      "training_loss: 0.5107614509761333\n",
      "validation_loss: 0.49773497581481935\n",
      "train_accuracy: 0.556875\n",
      "validation_accuracy: 0.59\n",
      "epoch: 43\n",
      "training_loss: 0.5109261944890022\n",
      "validation_loss: 0.5060021638870239\n",
      "train_accuracy: 0.5575\n",
      "validation_accuracy: 0.59\n",
      "epoch: 44\n",
      "training_loss: 0.5156128313392401\n",
      "validation_loss: 0.49924365282058714\n",
      "train_accuracy: 0.555\n",
      "validation_accuracy: 0.59\n",
      "epoch: 45\n",
      "training_loss: 0.5097083877772093\n",
      "validation_loss: 0.5131178498268127\n",
      "train_accuracy: 0.555625\n",
      "validation_accuracy: 0.588\n",
      "epoch: 46\n",
      "training_loss: 0.5103465970605612\n",
      "validation_loss: 0.4990177094936371\n",
      "train_accuracy: 0.55375\n",
      "validation_accuracy: 0.588\n",
      "epoch: 47\n",
      "training_loss: 0.5063299331814051\n",
      "validation_loss: 0.5045539617538453\n",
      "train_accuracy: 0.55875\n",
      "validation_accuracy: 0.59\n",
      "epoch: 48\n",
      "training_loss: 0.5082974880933762\n",
      "validation_loss: 0.4987015604972839\n",
      "train_accuracy: 0.555625\n",
      "validation_accuracy: 0.586\n",
      "epoch: 49\n",
      "training_loss: 0.5172023121267557\n",
      "validation_loss: 0.5071792483329773\n",
      "train_accuracy: 0.556875\n",
      "validation_accuracy: 0.588\n",
      "epoch: 50\n",
      "training_loss: 0.5193137843161821\n",
      "validation_loss: 0.49782798290252683\n",
      "train_accuracy: 0.56\n",
      "validation_accuracy: 0.588\n",
      "epoch: 51\n",
      "training_loss: 0.5108236987143755\n",
      "validation_loss: 0.500564581155777\n",
      "train_accuracy: 0.5575\n",
      "validation_accuracy: 0.588\n",
      "epoch: 52\n",
      "training_loss: 0.5098016727715731\n",
      "validation_loss: 0.49806920289993284\n",
      "train_accuracy: 0.556875\n",
      "validation_accuracy: 0.586\n",
      "epoch: 53\n",
      "training_loss: 0.5110623203217983\n",
      "validation_loss: 0.49933900833129885\n",
      "train_accuracy: 0.554375\n",
      "validation_accuracy: 0.59\n",
      "epoch: 54\n",
      "training_loss: 0.509185554459691\n",
      "validation_loss: 0.49936871528625487\n",
      "train_accuracy: 0.55625\n",
      "validation_accuracy: 0.586\n",
      "epoch: 55\n",
      "training_loss: 0.5100897178053856\n",
      "validation_loss: 0.4994096100330353\n",
      "train_accuracy: 0.556875\n",
      "validation_accuracy: 0.59\n",
      "epoch: 56\n",
      "training_loss: 0.5070890132337809\n",
      "validation_loss: 0.4967120587825775\n",
      "train_accuracy: 0.55375\n",
      "validation_accuracy: 0.59\n",
      "epoch: 57\n",
      "training_loss: 0.5107138585299253\n",
      "validation_loss: 0.5005605101585389\n",
      "train_accuracy: 0.558125\n",
      "validation_accuracy: 0.59\n",
      "epoch: 58\n",
      "training_loss: 0.5129510182887316\n",
      "validation_loss: 0.49790228605270387\n",
      "train_accuracy: 0.555\n",
      "validation_accuracy: 0.59\n",
      "epoch: 59\n",
      "training_loss: 0.5124605055898428\n",
      "validation_loss: 0.501666647195816\n",
      "train_accuracy: 0.55625\n",
      "validation_accuracy: 0.59\n",
      "epoch: 60\n",
      "training_loss: 0.5171748418360949\n",
      "validation_loss: 0.5003691196441651\n",
      "train_accuracy: 0.5575\n",
      "validation_accuracy: 0.588\n",
      "epoch: 61\n",
      "training_loss: 0.5098708365112543\n",
      "validation_loss: 0.4996848702430725\n",
      "train_accuracy: 0.555\n",
      "validation_accuracy: 0.588\n",
      "epoch: 62\n",
      "training_loss: 0.5134957730770111\n",
      "validation_loss: 0.502454799413681\n",
      "train_accuracy: 0.555\n",
      "validation_accuracy: 0.588\n",
      "epoch: 63\n",
      "training_loss: 0.5182863418012857\n",
      "validation_loss: 0.5078168094158173\n",
      "train_accuracy: 0.555\n",
      "validation_accuracy: 0.59\n",
      "epoch: 64\n",
      "training_loss: 0.5099556278437376\n",
      "validation_loss: 0.5012293875217437\n",
      "train_accuracy: 0.55625\n",
      "validation_accuracy: 0.588\n",
      "epoch: 65\n",
      "training_loss: 0.5149697568267584\n",
      "validation_loss: 0.5023522078990936\n",
      "train_accuracy: 0.55375\n",
      "validation_accuracy: 0.59\n",
      "epoch: 66\n",
      "training_loss: 0.5240460559725761\n",
      "validation_loss: 0.5055000841617584\n",
      "train_accuracy: 0.556875\n",
      "validation_accuracy: 0.59\n",
      "epoch: 67\n",
      "training_loss: 0.5149365477263927\n",
      "validation_loss: 0.49696735143661497\n",
      "train_accuracy: 0.555625\n",
      "validation_accuracy: 0.59\n",
      "epoch: 68\n",
      "training_loss: 0.5077038947492838\n",
      "validation_loss: 0.49720434546470643\n",
      "train_accuracy: 0.56\n",
      "validation_accuracy: 0.59\n",
      "epoch: 69\n",
      "training_loss: 0.5119216926395893\n",
      "validation_loss: 0.49868044853210447\n",
      "train_accuracy: 0.554375\n",
      "validation_accuracy: 0.588\n",
      "epoch: 70\n",
      "training_loss: 0.5125880092382431\n",
      "validation_loss: 0.49925574064254763\n",
      "train_accuracy: 0.555625\n",
      "validation_accuracy: 0.588\n",
      "epoch: 71\n",
      "training_loss: 0.510911175981164\n",
      "validation_loss: 0.4973935604095459\n",
      "train_accuracy: 0.556875\n",
      "validation_accuracy: 0.59\n",
      "epoch: 72\n",
      "training_loss: 0.5132048167288303\n",
      "validation_loss: 0.4979748487472534\n",
      "train_accuracy: 0.553125\n",
      "validation_accuracy: 0.588\n",
      "epoch: 73\n",
      "training_loss: 0.5081575568765402\n",
      "validation_loss: 0.5037730276584625\n",
      "train_accuracy: 0.5575\n",
      "validation_accuracy: 0.59\n",
      "epoch: 74\n",
      "training_loss: 0.5123288240283728\n",
      "validation_loss: 0.49717851281166076\n",
      "train_accuracy: 0.55625\n",
      "validation_accuracy: 0.586\n",
      "epoch: 75\n",
      "training_loss: 0.5110609382390976\n",
      "validation_loss: 0.49477003812789916\n",
      "train_accuracy: 0.553125\n",
      "validation_accuracy: 0.59\n",
      "epoch: 76\n",
      "training_loss: 0.5064148455858231\n",
      "validation_loss: 0.49689467549324035\n",
      "train_accuracy: 0.558125\n",
      "validation_accuracy: 0.588\n",
      "epoch: 77\n",
      "training_loss: 0.5092305801808834\n",
      "validation_loss: 0.4975494384765625\n",
      "train_accuracy: 0.55625\n",
      "validation_accuracy: 0.588\n",
      "epoch: 78\n",
      "training_loss: 0.5073316153138876\n",
      "validation_loss: 0.4982549726963043\n",
      "train_accuracy: 0.55875\n",
      "validation_accuracy: 0.586\n",
      "epoch: 79\n",
      "training_loss: 0.5099369138479233\n",
      "validation_loss: 0.5029145777225494\n",
      "train_accuracy: 0.556875\n",
      "validation_accuracy: 0.59\n",
      "epoch: 80\n",
      "training_loss: 0.5123309791088104\n",
      "validation_loss: 0.49839894771575927\n",
      "train_accuracy: 0.555\n",
      "validation_accuracy: 0.59\n",
      "epoch: 81\n",
      "training_loss: 0.5118613764643669\n",
      "validation_loss: 0.49894192814826965\n",
      "train_accuracy: 0.556875\n",
      "validation_accuracy: 0.59\n",
      "epoch: 82\n",
      "training_loss: 0.5106402579694986\n",
      "validation_loss: 0.4984789788722992\n",
      "train_accuracy: 0.553125\n",
      "validation_accuracy: 0.59\n",
      "epoch: 83\n",
      "training_loss: 0.5087724030017853\n",
      "validation_loss: 0.5094739675521851\n",
      "train_accuracy: 0.556875\n",
      "validation_accuracy: 0.59\n",
      "epoch: 84\n",
      "training_loss: 0.5134390089660883\n",
      "validation_loss: 0.5075626909732819\n",
      "train_accuracy: 0.5575\n",
      "validation_accuracy: 0.59\n",
      "epoch: 85\n",
      "training_loss: 0.5043089594691992\n",
      "validation_loss: 0.49654935002326966\n",
      "train_accuracy: 0.5575\n",
      "validation_accuracy: 0.59\n",
      "epoch: 86\n",
      "training_loss: 0.5115751679986715\n",
      "validation_loss: 0.5011926233768463\n",
      "train_accuracy: 0.555625\n",
      "validation_accuracy: 0.59\n",
      "epoch: 87\n",
      "training_loss: 0.5162976738065481\n",
      "validation_loss: 0.49998949766159057\n",
      "train_accuracy: 0.55875\n",
      "validation_accuracy: 0.588\n",
      "epoch: 88\n",
      "training_loss: 0.5172446258366108\n",
      "validation_loss: 0.5006883203983307\n",
      "train_accuracy: 0.554375\n",
      "validation_accuracy: 0.588\n",
      "epoch: 89\n",
      "training_loss: 0.5089330412447453\n",
      "validation_loss: 0.5041926562786102\n",
      "train_accuracy: 0.556875\n",
      "validation_accuracy: 0.59\n",
      "epoch: 90\n",
      "training_loss: 0.5135373938828707\n",
      "validation_loss: 0.504008162021637\n",
      "train_accuracy: 0.555625\n",
      "validation_accuracy: 0.59\n",
      "epoch: 91\n",
      "training_loss: 0.5145260002464056\n",
      "validation_loss: 0.5049556374549866\n",
      "train_accuracy: 0.553125\n",
      "validation_accuracy: 0.588\n",
      "epoch: 92\n",
      "training_loss: 0.5039039552211761\n",
      "validation_loss: 0.49837934970855713\n",
      "train_accuracy: 0.55875\n",
      "validation_accuracy: 0.59\n",
      "epoch: 93\n",
      "training_loss: 0.5058877822011709\n",
      "validation_loss: 0.49843875765800477\n",
      "train_accuracy: 0.55875\n",
      "validation_accuracy: 0.59\n",
      "epoch: 94\n",
      "training_loss: 0.5135584659874439\n",
      "validation_loss: 0.5094379127025604\n",
      "train_accuracy: 0.555625\n",
      "validation_accuracy: 0.588\n",
      "epoch: 95\n",
      "training_loss: 0.513152128085494\n",
      "validation_loss: 0.5075848281383515\n",
      "train_accuracy: 0.555625\n",
      "validation_accuracy: 0.588\n",
      "epoch: 96\n",
      "training_loss: 0.5055032521486282\n",
      "validation_loss: 0.5003917872905731\n",
      "train_accuracy: 0.559375\n",
      "validation_accuracy: 0.588\n",
      "epoch: 97\n",
      "training_loss: 0.5094567574560642\n",
      "validation_loss: 0.5009884655475616\n",
      "train_accuracy: 0.553125\n",
      "validation_accuracy: 0.588\n",
      "epoch: 98\n",
      "training_loss: 0.5136909857392311\n",
      "validation_loss: 0.49934995770454405\n",
      "train_accuracy: 0.55625\n",
      "validation_accuracy: 0.59\n",
      "epoch: 99\n",
      "training_loss: 0.5074150320142508\n",
      "validation_loss: 0.49958149790763856\n",
      "train_accuracy: 0.556875\n",
      "validation_accuracy: 0.588\n",
      "epoch: 100\n",
      "training_loss: 0.5076887141913176\n",
      "validation_loss: 0.5071663856506348\n",
      "train_accuracy: 0.56\n",
      "validation_accuracy: 0.59\n",
      "epoch: 101\n",
      "training_loss: 0.5148771479725838\n",
      "validation_loss: 0.4998288869857788\n",
      "train_accuracy: 0.554375\n",
      "validation_accuracy: 0.588\n",
      "epoch: 102\n",
      "training_loss: 0.5062484461814165\n",
      "validation_loss: 0.4972949385643005\n",
      "train_accuracy: 0.5575\n",
      "validation_accuracy: 0.588\n",
      "epoch: 103\n",
      "training_loss: 0.5137032978236675\n",
      "validation_loss: 0.5039909362792969\n",
      "train_accuracy: 0.555625\n",
      "validation_accuracy: 0.59\n",
      "epoch: 104\n",
      "training_loss: 0.5070850141346455\n",
      "validation_loss: 0.5021426498889923\n",
      "train_accuracy: 0.555625\n",
      "validation_accuracy: 0.586\n",
      "epoch: 105\n",
      "training_loss: 0.5087601933628321\n",
      "validation_loss: 0.5003406524658203\n",
      "train_accuracy: 0.556875\n",
      "validation_accuracy: 0.586\n",
      "epoch: 106\n",
      "training_loss: 0.5120606664568186\n",
      "validation_loss: 0.5027598738670349\n",
      "train_accuracy: 0.555\n",
      "validation_accuracy: 0.586\n",
      "epoch: 107\n",
      "training_loss: 0.5148092117160559\n",
      "validation_loss: 0.49921717047691344\n",
      "train_accuracy: 0.554375\n",
      "validation_accuracy: 0.588\n",
      "epoch: 108\n",
      "training_loss: 0.5142425931990147\n",
      "validation_loss: 0.4990935444831848\n",
      "train_accuracy: 0.558125\n",
      "validation_accuracy: 0.588\n",
      "epoch: 109\n",
      "training_loss: 0.5106336586177349\n",
      "validation_loss: 0.5136273264884949\n",
      "train_accuracy: 0.555\n",
      "validation_accuracy: 0.59\n",
      "epoch: 110\n",
      "training_loss: 0.5081773269921541\n",
      "validation_loss: 0.49801973104476926\n",
      "train_accuracy: 0.55625\n",
      "validation_accuracy: 0.59\n",
      "epoch: 111\n",
      "training_loss: 0.5119351595640182\n",
      "validation_loss: 0.49982005953788755\n",
      "train_accuracy: 0.55375\n",
      "validation_accuracy: 0.588\n",
      "epoch: 112\n",
      "training_loss: 0.5072613637894392\n",
      "validation_loss: 0.49780874252319335\n",
      "train_accuracy: 0.556875\n",
      "validation_accuracy: 0.588\n",
      "epoch: 113\n",
      "training_loss: 0.5132886599749327\n",
      "validation_loss: 0.5025341928005218\n",
      "train_accuracy: 0.55625\n",
      "validation_accuracy: 0.59\n",
      "epoch: 114\n",
      "training_loss: 0.5141680371016264\n",
      "validation_loss: 0.4978740930557251\n",
      "train_accuracy: 0.553125\n",
      "validation_accuracy: 0.588\n",
      "epoch: 115\n",
      "training_loss: 0.5103319324553013\n",
      "validation_loss: 0.497435587644577\n",
      "train_accuracy: 0.559375\n",
      "validation_accuracy: 0.59\n",
      "epoch: 116\n",
      "training_loss: 0.5090702213346958\n",
      "validation_loss: 0.49671793580055235\n",
      "train_accuracy: 0.555625\n",
      "validation_accuracy: 0.59\n",
      "epoch: 117\n",
      "training_loss: 0.5076403189450502\n",
      "validation_loss: 0.49787131547927854\n",
      "train_accuracy: 0.55625\n",
      "validation_accuracy: 0.586\n",
      "epoch: 118\n",
      "training_loss: 0.5114465430378914\n",
      "validation_loss: 0.49900429844856264\n",
      "train_accuracy: 0.55875\n",
      "validation_accuracy: 0.59\n",
      "epoch: 119\n",
      "training_loss: 0.5139079503715038\n",
      "validation_loss: 0.4989897131919861\n",
      "train_accuracy: 0.555\n",
      "validation_accuracy: 0.586\n",
      "epoch: 120\n",
      "training_loss: 0.5175174120813608\n",
      "validation_loss: 0.49868725538253783\n",
      "train_accuracy: 0.554375\n",
      "validation_accuracy: 0.588\n",
      "epoch: 121\n",
      "training_loss: 0.5110326185822487\n",
      "validation_loss: 0.5026391088962555\n",
      "train_accuracy: 0.55375\n",
      "validation_accuracy: 0.588\n",
      "epoch: 122\n",
      "training_loss: 0.5094924867153168\n",
      "validation_loss: 0.5001414120197296\n",
      "train_accuracy: 0.556875\n",
      "validation_accuracy: 0.588\n",
      "epoch: 123\n",
      "training_loss: 0.512916186824441\n",
      "validation_loss: 0.5105778932571411\n",
      "train_accuracy: 0.555\n",
      "validation_accuracy: 0.584\n",
      "epoch: 124\n",
      "training_loss: 0.5126670096069574\n",
      "validation_loss: 0.5015535831451416\n",
      "train_accuracy: 0.555625\n",
      "validation_accuracy: 0.59\n",
      "epoch: 125\n",
      "training_loss: 0.5118910651654005\n",
      "validation_loss: 0.49951879382133485\n",
      "train_accuracy: 0.5575\n",
      "validation_accuracy: 0.586\n",
      "epoch: 126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss: 0.5139880739152431\n",
      "validation_loss: 0.500239896774292\n",
      "train_accuracy: 0.5525\n",
      "validation_accuracy: 0.588\n",
      "epoch: 127\n",
      "training_loss: 0.5142284948378801\n",
      "validation_loss: 0.5092838883399964\n",
      "train_accuracy: 0.5575\n",
      "validation_accuracy: 0.588\n",
      "epoch: 128\n",
      "training_loss: 0.5075231976807117\n",
      "validation_loss: 0.5023239612579345\n",
      "train_accuracy: 0.55375\n",
      "validation_accuracy: 0.588\n",
      "epoch: 129\n",
      "training_loss: 0.5140943117439747\n",
      "validation_loss: 0.49658443927764895\n",
      "train_accuracy: 0.555\n",
      "validation_accuracy: 0.59\n",
      "epoch: 130\n",
      "training_loss: 0.511064924299717\n",
      "validation_loss: 0.5049850821495057\n",
      "train_accuracy: 0.556875\n",
      "validation_accuracy: 0.59\n",
      "epoch: 131\n",
      "training_loss: 0.5102081038057804\n",
      "validation_loss: 0.49988868832588196\n",
      "train_accuracy: 0.554375\n",
      "validation_accuracy: 0.59\n",
      "epoch: 132\n",
      "training_loss: 0.5114692058414221\n",
      "validation_loss: 0.49880281686782835\n",
      "train_accuracy: 0.558125\n",
      "validation_accuracy: 0.588\n",
      "epoch: 133\n",
      "training_loss: 0.511620070785284\n",
      "validation_loss: 0.5004469335079194\n",
      "train_accuracy: 0.555\n",
      "validation_accuracy: 0.588\n",
      "epoch: 134\n",
      "training_loss: 0.5053961277008057\n",
      "validation_loss: 0.499029278755188\n",
      "train_accuracy: 0.558125\n",
      "validation_accuracy: 0.586\n",
      "epoch: 135\n",
      "training_loss: 0.5097188968211412\n",
      "validation_loss: 0.4951601028442383\n",
      "train_accuracy: 0.554375\n",
      "validation_accuracy: 0.59\n",
      "epoch: 136\n",
      "training_loss: 0.5092553477734327\n",
      "validation_loss: 0.496245801448822\n",
      "train_accuracy: 0.55625\n",
      "validation_accuracy: 0.59\n",
      "epoch: 137\n",
      "training_loss: 0.5043997652828693\n",
      "validation_loss: 0.4997201979160309\n",
      "train_accuracy: 0.558125\n",
      "validation_accuracy: 0.588\n",
      "epoch: 138\n",
      "training_loss: 0.5097882524132729\n",
      "validation_loss: 0.49894813895225526\n",
      "train_accuracy: 0.556875\n",
      "validation_accuracy: 0.59\n",
      "epoch: 139\n",
      "training_loss: 0.5104379560798407\n",
      "validation_loss: 0.4975686013698578\n",
      "train_accuracy: 0.555625\n",
      "validation_accuracy: 0.59\n",
      "epoch: 140\n",
      "training_loss: 0.5040082298219204\n",
      "validation_loss: 0.500240957736969\n",
      "train_accuracy: 0.556875\n",
      "validation_accuracy: 0.586\n",
      "epoch: 141\n",
      "training_loss: 0.5091079268604517\n",
      "validation_loss: 0.5010345578193665\n",
      "train_accuracy: 0.55875\n",
      "validation_accuracy: 0.584\n",
      "epoch: 142\n",
      "training_loss: 0.5095092337578535\n",
      "validation_loss: 0.49903362393379214\n",
      "train_accuracy: 0.555625\n",
      "validation_accuracy: 0.588\n",
      "epoch: 143\n",
      "training_loss: 0.5033643003553152\n",
      "validation_loss: 0.5053851187229157\n",
      "train_accuracy: 0.5575\n",
      "validation_accuracy: 0.588\n",
      "epoch: 144\n",
      "training_loss: 0.5103539973497391\n",
      "validation_loss: 0.4996893465518951\n",
      "train_accuracy: 0.554375\n",
      "validation_accuracy: 0.586\n",
      "epoch: 145\n",
      "training_loss: 0.5090573448687792\n",
      "validation_loss: 0.4977444648742676\n",
      "train_accuracy: 0.556875\n",
      "validation_accuracy: 0.59\n",
      "epoch: 146\n",
      "training_loss: 0.5095338989049196\n",
      "validation_loss: 0.5022972762584687\n",
      "train_accuracy: 0.555625\n",
      "validation_accuracy: 0.59\n",
      "epoch: 147\n",
      "training_loss: 0.5079867225140333\n",
      "validation_loss: 0.4971223771572113\n",
      "train_accuracy: 0.554375\n",
      "validation_accuracy: 0.59\n",
      "epoch: 148\n",
      "training_loss: 0.5114485416561365\n",
      "validation_loss: 0.49882930517196655\n",
      "train_accuracy: 0.555625\n",
      "validation_accuracy: 0.59\n",
      "epoch: 149\n",
      "training_loss: 0.5150356665253639\n",
      "validation_loss: 0.4959401309490204\n",
      "train_accuracy: 0.553125\n",
      "validation_accuracy: 0.59\n",
      "epoch: 150\n",
      "training_loss: 0.5111180916428566\n",
      "validation_loss: 0.4991207838058472\n",
      "train_accuracy: 0.55625\n",
      "validation_accuracy: 0.588\n",
      "epoch: 151\n",
      "training_loss: 0.5127004459500313\n",
      "validation_loss: 0.500616055727005\n",
      "train_accuracy: 0.55625\n",
      "validation_accuracy: 0.59\n",
      "epoch: 152\n",
      "training_loss: 0.5066306982189417\n",
      "validation_loss: 0.5031428873538971\n",
      "train_accuracy: 0.55875\n",
      "validation_accuracy: 0.588\n",
      "epoch: 153\n",
      "training_loss: 0.505935825407505\n",
      "validation_loss: 0.49620535373687746\n",
      "train_accuracy: 0.55875\n",
      "validation_accuracy: 0.59\n",
      "epoch: 154\n",
      "training_loss: 0.5049480348825455\n",
      "validation_loss: 0.49738994240760803\n",
      "train_accuracy: 0.55625\n",
      "validation_accuracy: 0.586\n",
      "epoch: 155\n",
      "training_loss: 0.5092238187789917\n",
      "validation_loss: 0.4978747069835663\n",
      "train_accuracy: 0.5575\n",
      "validation_accuracy: 0.586\n",
      "epoch: 156\n",
      "training_loss: 0.5061894301325083\n",
      "validation_loss: 0.4986223876476288\n",
      "train_accuracy: 0.558125\n",
      "validation_accuracy: 0.588\n",
      "epoch: 157\n",
      "training_loss: 0.5103464890271425\n",
      "validation_loss: 0.5011760473251343\n",
      "train_accuracy: 0.55375\n",
      "validation_accuracy: 0.588\n",
      "epoch: 158\n",
      "training_loss: 0.5179753694683313\n",
      "validation_loss: 0.5011908888816834\n",
      "train_accuracy: 0.554375\n",
      "validation_accuracy: 0.59\n",
      "epoch: 159\n",
      "training_loss: 0.5081766210496426\n",
      "validation_loss: 0.4972243428230286\n",
      "train_accuracy: 0.555625\n",
      "validation_accuracy: 0.59\n",
      "epoch: 160\n",
      "training_loss: 0.5134905185550451\n",
      "validation_loss: 0.5014208137989045\n",
      "train_accuracy: 0.555\n",
      "validation_accuracy: 0.586\n",
      "epoch: 161\n",
      "training_loss: 0.5116743426769972\n",
      "validation_loss: 0.4969311773777008\n",
      "train_accuracy: 0.556875\n",
      "validation_accuracy: 0.59\n",
      "epoch: 162\n",
      "training_loss: 0.509608794003725\n",
      "validation_loss: 0.5014678716659546\n",
      "train_accuracy: 0.556875\n",
      "validation_accuracy: 0.59\n",
      "epoch: 163\n",
      "training_loss: 0.5083493664860725\n",
      "validation_loss: 0.49904399514198305\n",
      "train_accuracy: 0.56\n",
      "validation_accuracy: 0.588\n",
      "epoch: 164\n",
      "training_loss: 0.5167748853564262\n",
      "validation_loss: 0.49718900918960574\n",
      "train_accuracy: 0.55375\n",
      "validation_accuracy: 0.588\n",
      "epoch: 165\n",
      "training_loss: 0.5073397550731897\n",
      "validation_loss: 0.4992723286151886\n",
      "train_accuracy: 0.5575\n",
      "validation_accuracy: 0.588\n",
      "epoch: 166\n",
      "training_loss: 0.5112172458320856\n",
      "validation_loss: 0.5048650681972504\n",
      "train_accuracy: 0.555625\n",
      "validation_accuracy: 0.59\n",
      "epoch: 167\n",
      "training_loss: 0.5135220773518085\n",
      "validation_loss: 0.49852333664894105\n",
      "train_accuracy: 0.5525\n",
      "validation_accuracy: 0.588\n",
      "epoch: 168\n",
      "training_loss: 0.5163852032274008\n",
      "validation_loss: 0.5031740844249726\n",
      "train_accuracy: 0.555625\n",
      "validation_accuracy: 0.59\n",
      "epoch: 169\n",
      "training_loss: 0.5123954676091671\n",
      "validation_loss: 0.5003649234771729\n",
      "train_accuracy: 0.55625\n",
      "validation_accuracy: 0.59\n",
      "epoch: 170\n",
      "training_loss: 0.5142863616347313\n",
      "validation_loss: 0.5079248309135437\n",
      "train_accuracy: 0.554375\n",
      "validation_accuracy: 0.586\n",
      "epoch: 171\n",
      "training_loss: 0.5158815160393715\n",
      "validation_loss: 0.5025684237480164\n",
      "train_accuracy: 0.55375\n",
      "validation_accuracy: 0.584\n",
      "epoch: 172\n",
      "training_loss: 0.5136246997863054\n",
      "validation_loss: 0.4983448266983032\n",
      "train_accuracy: 0.556875\n",
      "validation_accuracy: 0.59\n",
      "epoch: 173\n",
      "training_loss: 0.5109665654599667\n",
      "validation_loss: 0.5003138363361359\n",
      "train_accuracy: 0.55625\n",
      "validation_accuracy: 0.59\n",
      "epoch: 174\n",
      "training_loss: 0.5073973406106234\n",
      "validation_loss: 0.5016786217689514\n",
      "train_accuracy: 0.5575\n",
      "validation_accuracy: 0.588\n",
      "epoch: 175\n",
      "training_loss: 0.5095698460936546\n",
      "validation_loss: 0.5024471342563629\n",
      "train_accuracy: 0.558125\n",
      "validation_accuracy: 0.59\n",
      "epoch: 176\n",
      "training_loss: 0.5086228903383017\n",
      "validation_loss: 0.49829562902450564\n",
      "train_accuracy: 0.555\n",
      "validation_accuracy: 0.588\n",
      "epoch: 177\n",
      "training_loss: 0.5018604770302773\n",
      "validation_loss: 0.49782145619392393\n",
      "train_accuracy: 0.55875\n",
      "validation_accuracy: 0.586\n",
      "epoch: 178\n",
      "training_loss: 0.5110167860984802\n",
      "validation_loss: 0.5092205882072449\n",
      "train_accuracy: 0.555625\n",
      "validation_accuracy: 0.586\n",
      "epoch: 179\n",
      "training_loss: 0.5124056357890368\n",
      "validation_loss: 0.5047507286071777\n",
      "train_accuracy: 0.55625\n",
      "validation_accuracy: 0.59\n",
      "epoch: 180\n",
      "training_loss: 0.5126160904765129\n",
      "validation_loss: 0.5020586013793945\n",
      "train_accuracy: 0.553125\n",
      "validation_accuracy: 0.59\n",
      "epoch: 181\n",
      "training_loss: 0.5115006100386381\n",
      "validation_loss: 0.5082274556159974\n",
      "train_accuracy: 0.556875\n",
      "validation_accuracy: 0.588\n",
      "epoch: 182\n",
      "training_loss: 0.5121972467750311\n",
      "validation_loss: 0.5010893821716309\n",
      "train_accuracy: 0.55625\n",
      "validation_accuracy: 0.59\n",
      "epoch: 183\n",
      "training_loss: 0.5102838277816772\n",
      "validation_loss: 0.5001370131969451\n",
      "train_accuracy: 0.559375\n",
      "validation_accuracy: 0.59\n",
      "epoch: 184\n",
      "training_loss: 0.5010887309908867\n",
      "validation_loss: 0.500899463891983\n",
      "train_accuracy: 0.558125\n",
      "validation_accuracy: 0.588\n",
      "epoch: 185\n",
      "training_loss: 0.5110267456620932\n",
      "validation_loss: 0.5024020433425903\n",
      "train_accuracy: 0.554375\n",
      "validation_accuracy: 0.59\n",
      "epoch: 186\n",
      "training_loss: 0.513154748827219\n",
      "validation_loss: 0.4959804773330688\n",
      "train_accuracy: 0.554375\n",
      "validation_accuracy: 0.59\n",
      "epoch: 187\n",
      "training_loss: 0.5118881929665804\n",
      "validation_loss: 0.4956356406211853\n",
      "train_accuracy: 0.554375\n",
      "validation_accuracy: 0.59\n",
      "epoch: 188\n",
      "training_loss: 0.5078226402401924\n",
      "validation_loss: 0.50199756026268\n",
      "train_accuracy: 0.560625\n",
      "validation_accuracy: 0.59\n",
      "epoch: 189\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-92473a8a6438>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"epoch:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mtrain_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrnn_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mvalidation_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrnn_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"training_loss:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-1a981c3abd73>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(data_loader, classifier, loss_function, optimizer)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;31m# print(predictions.type(), labels.type())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \"\"\"\n\u001b[1;32m--> 166\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "for epoch in range(0, epochs):\n",
    "    print(\"epoch:\", epoch + 1)\n",
    "    train_predictions, training_loss = train(train_loader, rnn_model, loss_function, optimizer)\n",
    "    validation_predictions, validation_loss = validation(valid_loader, rnn_model, loss_function, optimizer)\n",
    "    print(\"training_loss:\", training_loss)\n",
    "    print(\"validation_loss:\", validation_loss)\n",
    "    \n",
    "    print(\"train_accuracy:\", get_accuracy(train_predictions))\n",
    "    print(\"validation_accuracy:\", get_accuracy(validation_predictions))\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "y4EGJwSW6axL",
    "outputId": "5f8ed98e-1c6b-47a5-e70c-b7e6e9c31c6a"
   },
   "outputs": [],
   "source": [
    "train_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O9MPQlXH8nVG"
   },
   "outputs": [],
   "source": [
    "import matplotlib as plt\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aKAndDymnJrS"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "nlp_project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
